# Use PyTorch base image
FROM pytorch/pytorch:2.1.1-cuda12.1-cudnn8-runtime

# Set environment variables
ENV PYTHONPATH=/app
ENV CUDA_VISIBLE_DEVICES=0
ENV TORCH_USE_CUDA_DSA=1
ENV CUDA_LAUNCH_BLOCKING=1
ENV IS_SERVER=true
# Set non-interactive installation
ENV DEBIAN_FRONTEND=noninteractive
ENV TZ=UTC

# Install minimal system dependencies
RUN apt-get update && apt-get install -y \
    wget \
    sqlite3 \
    && rm -rf /var/lib/apt/lists/*

# Create necessary directories
RUN mkdir -p /app/api /app/models /app/logs /app/data /app/cache /app/database

# Set working directory
WORKDIR /app

# Copy only requirements first to leverage Docker cache
COPY api/requirements.txt requirements.txt

# Install Python dependencies (excluding PyTorch as it's in base image)
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY api/ /app/api/

# Create required directories first
RUN mkdir -p /app/data/partitioned /app/cache/torch /app/logs

# Copy only coordinator-specific data
COPY data/partitioned/server /app/data/partitioned/server
COPY data/identity_mapping.json /app/data/

# Copy coordinator model files
COPY models/server_model.pth /app/models/server_model.pth
COPY models/best_pretrained_model.pth /app/models/best_pretrained_model.pth

# Create placeholder database if it doesn't exist (but not model files)
RUN touch /app/database/federated.db

# Expose coordinator port
EXPOSE 8080

# Start coordinator
CMD ["sh", "-c", "python api/scripts/setup_models_and_mapping.py && uvicorn api.src.coordinator:app --host 0.0.0.0 --port 8080 --reload"] 