"""
Privacy-Preserving Federated Biometric Training System

This module implements comprehensive privacy-preserving federated learning
for biometric authentication using partitioned facial recognition data
with differential privacy and homomorphic encryption.
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import numpy as np
import json
import time
from datetime import datetime
from typing import Dict, List, Tuple, Optional, Any
from pathlib import Path
import logging
from collections import defaultdict
import math
import os
from tqdm import tqdm, trange

# Import our privacy components
from privacy_biometric_model import PrivacyBiometricModel, PrivacyAccountant, FederatedModelManager

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PrivacyFederatedTrainer:
    """
    Privacy-Preserving Federated Learning Trainer for Biometric Authentication
    
    Features:
    - Differential Privacy with budget tracking
    - Homomorphic encryption simulation
    - Federated averaging with privacy preservation
    - Partitioned data handling (server/client1/client2)
    - Client dropout tolerance
    - Convergence monitoring
    """
    
    def __init__(self, 
                 config: Dict[str, Any],
                 data_loaders: Dict[str, DataLoader],
                 save_dir: str = "federated_training_results",
                 stats_tracker=None):
        """
        Initialize Privacy-Infused Federated Trainer
        
        Args:
            config: Training configuration dictionary
            data_loaders: Dictionary of data loaders for each node
            save_dir: Directory to save training results
            stats_tracker: Statistics tracker for logging
        """
        self.config = config
        self.data_loaders = data_loaders
        self.save_dir = Path(save_dir)
        self.save_dir.mkdir(exist_ok=True)
        self.stats_tracker = stats_tracker
        
        # Initialize federated components
        self.model_manager = FederatedModelManager(
            num_identities=config.get('num_identities', 300)
        )
        
        # Create models for each node
        self.models = {}
        self.optimizers = {}
        self.privacy_accountants = {}
        
        for node_id in data_loaders.keys():
            self.models[node_id] = self.model_manager.create_node_model(
                node_id, privacy_enabled=config.get('enable_differential_privacy_federated', True)
            )
            
            # Initialize optimizer with privacy-friendly settings
            self.optimizers[node_id] = optim.Adam(
                self.models[node_id].parameters(),
                lr=config.get('learning_rate', 0.001),
                weight_decay=config.get('weight_decay', 1e-4)
            )
            
            # Initialize privacy accountant for each node
            self.privacy_accountants[node_id] = PrivacyAccountant(
                max_epsilon=config.get('max_epsilon', 1.0),
                delta=config.get('delta', 1e-5)
            )
        
        # Create global model
        self.global_model = self.model_manager.create_global_model()
        # Update global model privacy setting
        self.global_model.privacy_enabled = config.get('enable_differential_privacy_federated', True)
        
        # Training state
        self.current_round = 0
        self.training_history = []
        self.convergence_monitor = ConvergenceMonitor(
            patience=config.get('patience', 10),
            min_delta=config.get('min_delta', 0.001)
        )
        
        # Privacy and security settings
        self.noise_multiplier = config.get('noise_multiplier', 1.0)
        self.max_grad_norm = config.get('max_grad_norm', 1.0)
        self.homomorphic_encryption = config.get('use_homomorphic_encryption', True)
        
        # Track best accuracy
        self.best_global_acc = 0.0
        
        logger.info(f"Initialized Privacy-Infused Federated Trainer")
        logger.info(f"Nodes: {list(data_loaders.keys())}")
        logger.info(f"Privacy budget per node: Îµ={config.get('max_epsilon', 1.0)}")
        logger.info(f"Noise multiplier: Ïƒ={self.noise_multiplier}")
        
        if self.stats_tracker:
            print("ðŸ“Š Statistics tracking enabled")

    def _aggregate_models(self):
        """
        Aggregate client models into the global model using secure aggregation.
        This method coordinates the secure aggregation process with privacy preservation.
        """
        logger.info("\nðŸ”„ Starting secure model aggregation process...")
        
        # Extract and encrypt gradients from each client model
        local_results = {}
        for node_id, model in self.models.items():
            if node_id == 'server':
                continue
                
            logger.info(f"\nðŸ“¦ Processing {node_id}:")
            
            # Extract gradients
            gradients = self._extract_gradients(model)
            grad_shapes = {name: grad.shape for name, grad in gradients.items()}
            logger.info(f"   â”œâ”€ Extracted gradients: {len(gradients)} layers")
            logger.info(f"   â”œâ”€ Layer shapes: {grad_shapes}")
            
            # Add differential privacy noise if enabled
            if self.config.get('enable_differential_privacy_federated', True):
                self._add_dp_noise_to_gradients(model, node_id)
                logger.info(f"   â”œâ”€ Added differential privacy noise (Ïƒ={self.noise_multiplier})")
            
            # Get dataset size for this node
            dataset_size = len(self.data_loaders[node_id].dataset)
            logger.info(f"   â”œâ”€ Dataset size: {dataset_size} samples")
            
            # Encrypt gradients if homomorphic encryption is enabled
            if self.homomorphic_encryption:
                encrypted_gradients = self._encrypt_gradients(gradients, node_id)
                logger.info(f"   â”œâ”€ Encrypted gradients using homomorphic encryption")
            else:
                encrypted_gradients = gradients
                logger.info(f"   â”œâ”€ Using raw gradients (encryption disabled)")
                
            # Format results with required information
            local_results[node_id] = {
                'encrypted_gradients': encrypted_gradients,
                'samples_processed': dataset_size,
                'node_id': node_id
            }
            logger.info(f"   â””â”€ Prepared contribution package")
        
        # Log overall contribution summary
        total_samples = sum(result['samples_processed'] for result in local_results.values())
        logger.info("\nðŸ“Š Contribution Summary:")
        for node_id, result in local_results.items():
            contribution_weight = (result['samples_processed'] / total_samples) * 100
            logger.info(f"   â”œâ”€ {node_id}: {result['samples_processed']} samples ({contribution_weight:.1f}% weight)")
        
        # Perform secure gradient aggregation
        logger.info("\nðŸ”’ Starting secure aggregation...")
        aggregation_results = self._secure_gradient_aggregation(local_results)
        
        # Update global model with aggregated gradients
        self._update_global_model(aggregation_results)
        
        # Broadcast updated global model to all clients
        logger.info("\nðŸ“¡ Broadcasting updated model to clients...")
        self._broadcast_global_model()
        
        logger.info("\nâœ… Completed secure model aggregation\n")

    def train_federated_round(self) -> Dict[str, Any]:
        """Execute one round of federated training"""
        self.current_round += 1
        round_start_time = time.time()
        
        # Track round statistics
        round_stats = {
            'client_losses': [],
            'client_accuracies': [],
            'active_nodes': [],
            'privacy_status': {
                'active_nodes': [],
                'budget_exhausted': {},
                'client_privacy': {}
            }
        }
        
        # Client training phase
        for node_id, model in self.models.items():
            if node_id == 'server':
                continue
                
            # Check privacy budget
            if self.config['enable_differential_privacy_federated']:
                accountant = self.privacy_accountants[node_id]
                if accountant.is_budget_exhausted():
                    logger.warning(f"âš ï¸ {node_id}: Privacy budget exhausted")
                    round_stats['privacy_status']['budget_exhausted'][node_id] = True
                    continue
            
            round_stats['privacy_status']['active_nodes'].append(node_id)
            round_stats['privacy_status']['budget_exhausted'][node_id] = False
            
            # Train client model
            client_stats = self._train_client(node_id, model)
            
            # Update round statistics
            round_stats['client_losses'].append(client_stats['loss'])
            round_stats['client_accuracies'].append(client_stats['accuracy'])
            
            # Track privacy metrics
            if self.config['enable_differential_privacy_federated']:
                privacy_metrics = accountant.get_privacy_stats()
                round_stats['privacy_status']['client_privacy'][node_id] = privacy_metrics
                
                # Log privacy metrics if stats tracker is available
                if self.stats_tracker:
                    self.stats_tracker.log_privacy_metrics(
                        self.current_round,
                        node_id,
                        privacy_metrics
                    )
        
        # Global model aggregation
        self._aggregate_models()
        
        # Evaluate global model
        global_eval = self._evaluate_global_model()
        
        # Calculate round statistics
        round_stats['avg_client_loss'] = np.mean(round_stats['client_losses']) if round_stats['client_losses'] else 0
        round_stats['avg_client_accuracy'] = np.mean(round_stats['client_accuracies']) if round_stats['client_accuracies'] else 0
        round_stats['global_evaluation'] = global_eval
        round_stats['round_time'] = time.time() - round_start_time
        
        # Log federated round statistics if stats tracker is available
        if self.stats_tracker:
            self.stats_tracker.log_federated_stats(self.current_round, {
                'global_loss': global_eval['loss'],
                'global_acc': global_eval['accuracy'],
                'avg_client_loss': round_stats['avg_client_loss'],
                'avg_client_acc': round_stats['avg_client_accuracy'],
                'active_clients': len(round_stats['privacy_status']['active_nodes'])
            })
        
        # Save best model
        if global_eval['accuracy'] > self.best_global_acc:
            self.best_global_acc = global_eval['accuracy']
            torch.save(self.global_model.state_dict(), 
                      os.path.join(self.save_dir, 'best_global_model.pth'))
            logger.info(f"ðŸ’¾ Saved new best global model (acc: {self.best_global_acc:.4f})")
        
        # Check if any client has exhausted privacy budget
        if all(round_stats['privacy_status']['budget_exhausted'].values()):
            round_stats['stopped_early'] = True
            logger.warning("âš ï¸ All clients have exhausted privacy budget")
        
        return round_stats

    def _broadcast_global_model(self):
        """Broadcast global model weights to all client nodes"""
        logger.info("Broadcasting global model to all clients...")
        
        if self.global_model is not None:
            global_state = self.global_model.state_dict()
            
            for node_id, model in self.models.items():
                model.load_state_dict(global_state)
                logger.debug(f"Model synchronized to {node_id}")
        
        logger.info("âœ“ Global model broadcast complete")

    def _execute_local_training(self) -> Dict[str, Any]:
        """Execute local training on all nodes with differential privacy"""
        logger.info("Executing local training with differential privacy...")
        
        local_results = {}
        
        for node_id, model in self.models.items():
            if node_id not in self.data_loaders:
                logger.warning(f"No data loader for {node_id}, skipping")
                continue
            
            logger.info(f"Training on {node_id}...")
            
            # Check if node can still train (privacy budget)
            if not self.privacy_accountants[node_id].can_train():
                logger.warning(f"{node_id} privacy budget exhausted, skipping")
                continue
            
            # Local training with privacy
            node_results = self._train_local_node(node_id, model)
            local_results[node_id] = node_results
            
            logger.info(f"âœ“ {node_id} training complete: "
                       f"loss={node_results['final_loss']:.4f}, "
                       f"accuracy={node_results['accuracy']:.3f}")
        
        return local_results

    def _train_local_node(self, node_id: str, model: nn.Module) -> Dict[str, Any]:
        """Train a single node with differential privacy"""
        # GPU setup and monitoring
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model = model.to(device)
        
        if torch.cuda.is_available():
            torch.cuda.empty_cache()  # Clear GPU cache
            gpu_memory_before = torch.cuda.memory_allocated() / 1024**3
            logger.info(f"ðŸŽ® {node_id} GPU Memory before training: {gpu_memory_before:.2f}GB")
            logger.info(f"ðŸš€ {node_id} training on GPU: {torch.cuda.get_device_name(0)}")
        else:
            logger.warning(f"âš ï¸  {node_id} training on CPU (GPU not available)")
        
        model.train()
        optimizer = self.optimizers[node_id]
        data_loader = self.data_loaders[node_id]
        privacy_accountant = self.privacy_accountants[node_id]
        
        # Training metrics
        total_loss = 0.0
        correct_predictions = 0
        total_samples = 0
        gradients_collected = []
        
        # Local training epochs
        if node_id == 'server':
            local_epochs = self.config.get('server_local_epochs', self.config.get('local_epochs', 5))
        else:
            local_epochs = self.config.get('client_local_epochs', self.config.get('local_epochs', 5))
        
        total_batches = len(data_loader)
        logger.info(f"ðŸ“š {node_id} training: {local_epochs} epochs Ã— {total_batches} batches = {local_epochs * total_batches} total steps")
        
        for epoch in range(local_epochs):
            epoch_loss = 0.0
            epoch_correct = 0
            epoch_samples = 0
            epoch_start_time = time.time()
            
            logger.info(f"ðŸ“Š {node_id} Epoch {epoch+1}/{local_epochs} starting...")
            
            for batch_idx, (images, identity_labels) in enumerate(data_loader):
                # Skip batch if size is 1 (BatchNorm requires batch_size > 1)
                if images.size(0) == 1:
                    logger.warning(f"{node_id} Skipping batch with size 1 (BatchNorm requirement)")
                    continue
                
                # Move data to GPU
                images = images.to(device)
                identity_labels = identity_labels.to(device)
                
                # Forward pass - identity-only model returns (identity_logits, features)
                identity_logits, features = model(images, add_noise=True, node_id=node_id)
                
                # Compute loss
                loss = nn.CrossEntropyLoss()(identity_logits, identity_labels)
                
                # Backward pass
                optimizer.zero_grad()
                loss.backward()
                
                # Gradient clipping for differential privacy
                torch.nn.utils.clip_grad_norm_(model.parameters(), self.max_grad_norm)
                
                # Add differential privacy noise to gradients
                self._add_dp_noise_to_gradients(model, node_id)
                
                # Optimizer step
                optimizer.step()
                
                # Update metrics
                epoch_loss += loss.item()
                epoch_samples += images.size(0)
                
                # Calculate accuracy
                _, predicted = torch.max(identity_logits.data, 1)
                epoch_correct += (predicted == identity_labels).sum().item()
                
                # Privacy budget consumption
                epsilon_step = self._calculate_privacy_cost(
                    batch_size=images.size(0),
                    dataset_size=len(data_loader.dataset)
                )
                privacy_accountant.consume_privacy_budget(epsilon_step)
                
                # Progress logging every 100 batches
                if (batch_idx + 1) % 100 == 0 or batch_idx == 0:
                    current_acc = epoch_correct / max(1, epoch_samples) * 100
                    current_loss = epoch_loss / max(1, batch_idx + 1)
                    privacy_stats = privacy_accountant.get_privacy_stats()
                    
                    logger.info(f"ðŸ”„ {node_id} Epoch {epoch+1}/{local_epochs} | "
                              f"Batch {batch_idx+1}/{total_batches} | "
                              f"Loss: {current_loss:.4f} | "
                              f"Acc: {current_acc:.2f}% | "
                              f"Privacy Îµ: {privacy_stats['epsilon_used']:.4f}/{privacy_stats['epsilon_used'] + privacy_stats['epsilon_remaining']:.1f}")
                
                # Check privacy budget
                if not privacy_accountant.can_train():
                    logger.warning(f"{node_id} privacy budget exhausted during training")
                    break
            
            total_loss += epoch_loss
            correct_predictions += epoch_correct
            total_samples += epoch_samples
            
            # Epoch completion logging
            epoch_duration = time.time() - epoch_start_time
            epoch_acc = epoch_correct / max(1, epoch_samples) * 100
            epoch_avg_loss = epoch_loss / max(1, epoch_samples)
            
            if torch.cuda.is_available():
                gpu_memory_current = torch.cuda.memory_allocated() / 1024**3
                gpu_memory_cached = torch.cuda.memory_reserved() / 1024**3
                logger.info(f"âœ… {node_id} Epoch {epoch+1}/{local_epochs} completed | "
                          f"Loss: {epoch_avg_loss:.4f} | Acc: {epoch_acc:.2f}% | "
                          f"Time: {epoch_duration:.1f}s | "
                          f"GPU: {gpu_memory_current:.2f}GB/{gpu_memory_cached:.2f}GB")
            else:
                logger.info(f"âœ… {node_id} Epoch {epoch+1}/{local_epochs} completed | "
                          f"Loss: {epoch_avg_loss:.4f} | Acc: {epoch_acc:.2f}% | "
                          f"Time: {epoch_duration:.1f}s")
            
            if not privacy_accountant.can_train():
                break
        
        # Collect gradients for secure aggregation
        gradients = self._extract_gradients(model)
        
        # Encrypt gradients (simulation)
        if self.homomorphic_encryption:
            encrypted_gradients = self._encrypt_gradients(gradients, node_id)
        else:
            encrypted_gradients = gradients
        
        return {
            'node_id': node_id,
            'final_loss': total_loss / max(1, total_samples),
            'accuracy': correct_predictions / max(1, total_samples),
            'samples_processed': total_samples,
            'encrypted_gradients': encrypted_gradients,
            'privacy_stats': privacy_accountant.get_privacy_stats(),
            'training_epochs_completed': local_epochs
        }

    def _add_dp_noise_to_gradients(self, model: nn.Module, node_id: str):
        """Add differential privacy noise to model gradients"""
        with torch.no_grad():
            for param in model.parameters():
                if param.grad is not None:
                    # Calculate noise scale based on sensitivity and privacy parameters
                    noise_scale = self.noise_multiplier * self.max_grad_norm
                    
                    # Add Gaussian noise
                    noise = torch.normal(
                        mean=0.0, 
                        std=noise_scale, 
                        size=param.grad.shape,
                        device=param.grad.device
                    )
                    param.grad += noise

    def _calculate_privacy_cost(self, batch_size: int, dataset_size: int) -> float:
        """Calculate privacy cost (epsilon) for one training step"""
        # Much more conservative privacy cost calculation for longer training
        q = batch_size / dataset_size  # Sampling probability
        
        # Using simplified composition theorem with very conservative bounds
        # Adjusted for much longer training with higher privacy budget
        epsilon_step = (q * math.log(1.25 / self.config.get('delta', 1e-5))) / (self.noise_multiplier ** 2)
        
        # Scale down much more aggressively for better budget management
        epsilon_step = epsilon_step * 0.01  # Much more conservative scaling (10x less)
        
        return max(epsilon_step, 0.00001)  # Much lower minimum epsilon per step

    def _extract_gradients(self, model: nn.Module) -> Dict[str, torch.Tensor]:
        """Extract gradients from model parameters"""
        gradients = {}
        for name, param in model.named_parameters():
            if param.grad is not None:
                # Clone and detach gradients, keeping them on the same device
                gradients[name] = param.grad.clone().detach()
        return gradients

    def _encrypt_gradients(self, gradients: Dict[str, torch.Tensor], node_id: str) -> Dict[str, Any]:
        """Simulate homomorphic encryption of gradients"""
        # This is a simulation - in practice, use actual homomorphic encryption
        encrypted_gradients = {}
        
        logger.info(f"\nðŸ” Encrypting gradients for {node_id}:")
        logger.info(f"   â”œâ”€ Total layers: {len(gradients)}")
        
        # Track statistics for visualization
        total_params = 0
        param_stats = {}
        
        for name, grad in gradients.items():
            try:
                # Move tensor to CPU before converting to numpy
                grad_cpu = grad.detach().cpu()
                grad_np = grad_cpu.numpy()
                
                # Calculate some statistics
                param_count = np.prod(grad_np.shape)
                total_params += param_count
                mean_val = np.mean(grad_np)
                std_val = np.std(grad_np)
                
                param_stats[name] = {
                    'shape': grad_np.shape,
                    'mean': mean_val,
                    'std': std_val,
                    'min': np.min(grad_np),
                    'max': np.max(grad_np)
                }
                
                # Simulate encryption by adding a deterministic transformation
                encrypted_gradients[name] = {
                    'encrypted_data': grad_np.tolist(),
                    'encryption_params': {
                        'node_id': node_id,
                        'timestamp': datetime.now().isoformat(),
                        'encryption_scheme': 'CKKS_simulation',
                        'tensor_shape': list(grad.shape),
                        'tensor_device': str(grad.device)
                    }
                }
                
            except Exception as e:
                logger.error(f"Failed to encrypt gradient {name} for {node_id}: {e}")
                logger.error(f"Gradient shape: {grad.shape}, device: {grad.device}, dtype: {grad.dtype}")
                raise
        
        # Log summary statistics
        logger.info(f"   â”œâ”€ Total parameters: {total_params:,}")
        logger.info("   â””â”€ Layer statistics:")
        
        # Show stats for a few important layers
        important_layers = ['fc1.weight', 'fc2.weight', 'fc3.weight']
        for layer_name in important_layers:
            if layer_name in param_stats:
                stats = param_stats[layer_name]
                logger.info(f"      â”œâ”€ {layer_name}:")
                logger.info(f"      â”‚  â”œâ”€ Shape: {stats['shape']}")
                logger.info(f"      â”‚  â”œâ”€ Mean: {stats['mean']:.6f}")
                logger.info(f"      â”‚  â”œâ”€ Std: {stats['std']:.6f}")
                logger.info(f"      â”‚  â”œâ”€ Min: {stats['min']:.6f}")
                logger.info(f"      â”‚  â””â”€ Max: {stats['max']:.6f}")
        
        return encrypted_gradients

    def _secure_gradient_aggregation(self, local_results: Dict[str, Any]) -> Dict[str, Any]:
        """Perform secure gradient aggregation with homomorphic encryption"""
        if not local_results:
            logger.warning("No local results to aggregate")
            return {}
        
        # Calculate aggregation weights based on data sizes
        total_samples = sum(result['samples_processed'] for result in local_results.values())
        aggregation_weights = {
            node_id: result['samples_processed'] / total_samples
            for node_id, result in local_results.items()
        }
        
        logger.info("\nâš–ï¸ Aggregation weights:")
        for node_id, weight in aggregation_weights.items():
            logger.info(f"   â”œâ”€ {node_id}: {weight:.3f}")
        
        # Aggregate encrypted gradients
        aggregated_gradients = {}
        
        # Get parameter names from first node
        first_node = next(iter(local_results.keys()))
        if 'encrypted_gradients' not in local_results[first_node]:
            logger.warning("No encrypted gradients found in local results")
            return {
                'aggregated_gradients': {},
                'aggregation_weights': aggregation_weights,
                'participating_nodes': list(local_results.keys()),
                'total_samples': total_samples
            }
            
        param_names = local_results[first_node]['encrypted_gradients'].keys()
        logger.info(f"\nðŸ”„ Aggregating {len(param_names)} parameter layers...")
        
        # Track statistics for important layers
        important_layers = ['fc1.weight', 'fc2.weight', 'fc3.weight']
        layer_stats = {layer: {'before': {}, 'after': {}} for layer in important_layers}
        
        for param_name in param_names:
            # Homomorphic aggregation (simulation)
            weighted_gradients = []
            param_shape = None
            
            for node_id, result in local_results.items():
                if 'encrypted_gradients' not in result or param_name not in result['encrypted_gradients']:
                    continue
                    
                encrypted_grad = result['encrypted_gradients'][param_name]
                if not isinstance(encrypted_grad, dict) or 'encrypted_data' not in encrypted_grad:
                    logger.warning(f"Invalid gradient format for {param_name} from {node_id}")
                    continue
                
                # Simulate homomorphic operations
                try:
                    grad_data = np.array(encrypted_grad['encrypted_data'])
                    if param_shape is None:
                        param_shape = grad_data.shape
                    elif grad_data.shape != param_shape:
                        logger.warning(f"Shape mismatch for {param_name} from {node_id}")
                        continue
                        
                    weight = aggregation_weights[node_id]
                    weighted_grad = grad_data * weight
                    weighted_gradients.append(weighted_grad)
                    
                    # Track statistics for important layers
                    if param_name in important_layers:
                        layer_stats[param_name]['before'][node_id] = {
                            'mean': float(np.mean(grad_data)),
                            'std': float(np.std(grad_data)),
                            'min': float(np.min(grad_data)),
                            'max': float(np.max(grad_data)),
                            'weight': weight
                        }
                except Exception as e:
                    logger.error(f"Error processing gradients for {param_name} from {node_id}: {e}")
                    continue
            
            # Aggregate (sum in encrypted space)
            if weighted_gradients:
                try:
                    aggregated_grad = np.sum(weighted_gradients, axis=0)
                    aggregated_gradients[param_name] = aggregated_grad
                    
                    # Track statistics after aggregation for important layers
                    if param_name in important_layers:
                        layer_stats[param_name]['after'] = {
                            'mean': float(np.mean(aggregated_grad)),
                            'std': float(np.std(aggregated_grad)),
                            'min': float(np.min(aggregated_grad)),
                            'max': float(np.max(aggregated_grad))
                        }
                except Exception as e:
                    logger.error(f"Error aggregating gradients for {param_name}: {e}")
                    continue
        
        # Log detailed statistics for important layers
        logger.info("\nðŸ“Š Layer-wise aggregation statistics:")
        for layer_name in important_layers:
            if layer_name in layer_stats and layer_stats[layer_name]['before'] and 'after' in layer_stats[layer_name]:
                logger.info(f"\n   â”œâ”€ {layer_name}:")
                logger.info(f"   â”‚  â”œâ”€ Before aggregation (weighted):")
                for node_id, stats in layer_stats[layer_name]['before'].items():
                    logger.info(f"   â”‚  â”‚  â”œâ”€ {node_id} (weight={stats['weight']:.3f}):")
                    logger.info(f"   â”‚  â”‚  â”‚  â”œâ”€ Mean: {stats['mean']:.6f}")
                    logger.info(f"   â”‚  â”‚  â”‚  â”œâ”€ Std: {stats['std']:.6f}")
                    logger.info(f"   â”‚  â”‚  â”‚  â”œâ”€ Min: {stats['min']:.6f}")
                    logger.info(f"   â”‚  â”‚  â”‚  â””â”€ Max: {stats['max']:.6f}")
                
                after_stats = layer_stats[layer_name]['after']
                logger.info(f"   â”‚  â””â”€ After aggregation:")
                logger.info(f"   â”‚     â”œâ”€ Mean: {after_stats['mean']:.6f}")
                logger.info(f"   â”‚     â”œâ”€ Std: {after_stats['std']:.6f}")
                logger.info(f"   â”‚     â”œâ”€ Min: {after_stats['min']:.6f}")
                logger.info(f"   â”‚     â””â”€ Max: {after_stats['max']:.6f}")
        
        logger.info("\nâœ¨ Secure aggregation summary:")
        logger.info(f"   â”œâ”€ Total parameters aggregated: {len(aggregated_gradients)}")
        logger.info(f"   â”œâ”€ Participating nodes: {list(local_results.keys())}")
        logger.info(f"   â””â”€ Total samples considered: {total_samples}")
        
        return {
            'aggregated_gradients': aggregated_gradients,
            'aggregation_weights': aggregation_weights,
            'participating_nodes': list(local_results.keys()),
            'total_samples': total_samples
        }

    def _update_global_model(self, aggregation_results: Dict[str, Any]):
        """Update global model with aggregated gradients"""
        if not aggregation_results or 'aggregated_gradients' not in aggregation_results:
            logger.warning("No aggregated gradients to apply")
            return
        
        logger.info("Updating global model...")
        
        # Apply aggregated gradients to global model
        with torch.no_grad():
            for name, param in self.global_model.named_parameters():
                if name in aggregation_results['aggregated_gradients']:
                    # Convert back to tensor and apply
                    aggregated_grad = torch.tensor(
                        aggregation_results['aggregated_gradients'][name],
                        dtype=param.dtype,
                        device=param.device
                    )
                    
                    # Update parameter (simplified - in practice, use proper optimizer)
                    learning_rate = self.config.get('global_learning_rate', 0.01)
                    param -= learning_rate * aggregated_grad
        
        logger.info("âœ“ Global model updated")

    def _evaluate_global_model(self) -> Dict[str, float]:
        """Evaluate global model performance"""
        logger.info("\nðŸ“Š Evaluating global model...")
        
        # GPU setup
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.global_model = self.global_model.to(device)
        self.global_model.eval()
        
        if torch.cuda.is_available():
            logger.info(f"ðŸŽ® Using GPU: {torch.cuda.get_device_name(0)}")
        
        total_loss = 0.0
        correct_predictions = 0
        total_samples = 0
        
        # Create progress bar for nodes
        nodes_iter = tqdm(self.data_loaders.items(), desc="Evaluating nodes", unit="node")
        
        with torch.no_grad():
            for node_id, data_loader in nodes_iter:
                nodes_iter.set_postfix_str(f"Processing {node_id}")
                
                # Create progress bar for batches within this node
                batch_iter = tqdm(data_loader, 
                                desc=f"{node_id} batches",
                                unit="batch",
                                leave=False)
                
                node_correct = 0
                node_total = 0
                node_loss = 0.0
                
                for images, identity_labels in batch_iter:
                    # Skip batch if size is 1 (BatchNorm requires batch_size > 1)
                    if images.size(0) == 1:
                        continue
                    
                    # Move data to GPU
                    images = images.to(device)
                    identity_labels = identity_labels.to(device)
                    
                    # Forward pass - identity-only model returns (identity_logits, features)
                    identity_logits, features = self.global_model(images, add_noise=False, node_id="global")
                    
                    # Calculate loss
                    batch_loss = nn.CrossEntropyLoss()(identity_logits, identity_labels)
                    node_loss += batch_loss.item() * images.size(0)
                    
                    # Calculate accuracy
                    _, predicted = torch.max(identity_logits.data, 1)
                    batch_correct = (predicted == identity_labels).sum().item()
                    node_correct += batch_correct
                    node_total += images.size(0)
                    
                    # Update batch progress bar
                    batch_iter.set_postfix(
                        loss=f"{batch_loss.item():.4f}",
                        acc=f"{batch_correct/images.size(0):.3f}"
                    )
                
                # Update totals
                total_loss += node_loss
                correct_predictions += node_correct
                total_samples += node_total
                
                # Update node progress bar
                nodes_iter.set_postfix(
                    loss=f"{node_loss/node_total:.4f}",
                    acc=f"{node_correct/node_total:.3f}"
                )
        
        avg_loss = total_loss / max(1, total_samples)
        accuracy = correct_predictions / max(1, total_samples)
        
        logger.info(f"\nâœ¨ Global evaluation results:")
        logger.info(f"   â”œâ”€ Loss: {avg_loss:.4f}")
        logger.info(f"   â”œâ”€ Accuracy: {accuracy:.3f}")
        logger.info(f"   â””â”€ Samples evaluated: {total_samples}\n")
        
        return {
            'loss': avg_loss,
            'accuracy': accuracy,
            'total_samples': total_samples
        }

    def _check_privacy_budgets(self) -> Dict[str, Any]:
        """Check privacy budget status across all nodes"""
        budget_status = {}
        can_continue = True
        
        for node_id, accountant in self.privacy_accountants.items():
            stats = accountant.get_privacy_stats()
            budget_status[node_id] = stats
            
            if stats['budget_exhausted']:
                can_continue = False
        
        return {
            'can_continue': can_continue,
            'node_budgets': budget_status,
            'total_nodes': len(self.privacy_accountants),
            'active_nodes': sum(1 for stats in budget_status.values() if not stats['budget_exhausted'])
        }

    def _create_round_summary(self, local_results: Dict[str, Any], 
                            privacy_status: Dict[str, Any], 
                            round_start_time: float,
                            aggregation_results: Dict[str, Any] = None,
                            evaluation_results: Dict[str, float] = None,
                            convergence_status: Tuple[bool, Dict] = None,
                            stopped: bool = False) -> Dict[str, Any]:
        """Create comprehensive round summary"""
        round_duration = time.time() - round_start_time
        
        summary = {
            'round': self.current_round,
            'timestamp': datetime.now().isoformat(),
            'duration_seconds': round_duration,
            'stopped_early': stopped,
            'local_training': local_results,
            'privacy_status': privacy_status,
            'aggregation': aggregation_results or {},
            'global_evaluation': evaluation_results or {},
            'convergence': convergence_status[1] if convergence_status else {},
            'converged': convergence_status[0] if convergence_status else False
        }
        
        return summary

    def _save_round_results(self, round_summary: Dict[str, Any]):
        """Save round results to disk"""
        results_file = self.save_dir / f"round_{self.current_round:03d}_results.json"
        
        # Convert tensors to lists for JSON serialization
        serializable_summary = self._make_json_serializable(round_summary)
        
        with open(results_file, 'w') as f:
            json.dump(serializable_summary, f, indent=2)
        
        # Also append to training history
        self.training_history.append(serializable_summary)
        
        # Save complete training history
        history_file = self.save_dir / "training_history.json"
        with open(history_file, 'w') as f:
            json.dump(self.training_history, f, indent=2)

    def _make_json_serializable(self, obj):
        """Convert objects to JSON-serializable format"""
        if isinstance(obj, dict):
            return {k: self._make_json_serializable(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._make_json_serializable(item) for item in obj]
        elif isinstance(obj, torch.Tensor):
            return obj.tolist()
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif hasattr(obj, '__dict__'):
            return self._make_json_serializable(obj.__dict__)
        else:
            return obj

    def _log_round_summary(self, round_summary: Dict[str, Any]):
        """Log round summary to console"""
        logger.info(f"\nðŸ“Š ROUND {self.current_round} SUMMARY")
        logger.info(f"Duration: {round_summary['duration_seconds']:.1f}s")
        
        if 'global_evaluation' in round_summary and round_summary['global_evaluation']:
            eval_results = round_summary['global_evaluation']
            logger.info(f"Global Loss: {eval_results['loss']:.4f}")
            logger.info(f"Global Accuracy: {eval_results['accuracy']:.3f}")
        
        # Privacy status
        privacy_status = round_summary['privacy_status']
        logger.info(f"Active Nodes: {privacy_status['active_nodes']}/{privacy_status['total_nodes']}")
        
        # Convergence status
        if 'convergence' in round_summary and round_summary['convergence']:
            conv_status = round_summary['convergence']
            if round_summary.get('converged', False):
                logger.info("ðŸŽ‰ MODEL CONVERGED!")
            else:
                logger.info(f"Rounds without improvement: {conv_status.get('rounds_without_improvement', 0)}")

    def train_complete_federated_system(self, max_rounds: int = 100) -> Dict[str, Any]:
        """
        Train the complete federated system with privacy preservation
        
        Args:
            max_rounds: Maximum number of federated rounds
            
        Returns:
            Complete training results and statistics
        """
        logger.info(f"\nðŸš€ Starting Privacy-Infused Federated Training")
        logger.info(f"Max rounds: {max_rounds}")
        logger.info(f"Privacy budget per node: Îµ={self.config.get('max_epsilon', 1.0)}")
        
        training_start_time = time.time()
        
        # Add progress bar for rounds
        pbar = trange(1, max_rounds + 1, desc="Training Rounds", unit="round")
        for round_num in pbar:
            # Execute federated round
            round_results = self.train_federated_round()
            
            # Update progress bar description with metrics
            if 'global_evaluation' in round_results:
                pbar.set_postfix({
                    'loss': f"{round_results['global_evaluation']['loss']:.4f}",
                    'acc': f"{round_results['global_evaluation']['accuracy']:.3f}",
                    'active_nodes': len(round_results['privacy_status']['active_nodes'])
                })
            
            # Check stopping conditions
            if round_results.get('stopped_early', False):
                logger.info("Training stopped early due to privacy budget exhaustion")
                break
            
            if round_results.get('converged', False):
                logger.info("Training stopped due to convergence")
                break
            
            # Check if any nodes can still train
            if round_results['privacy_status']['active_nodes'] == 0:
                logger.info("No active nodes remaining, stopping training")
                break
        
        training_duration = time.time() - training_start_time
        
        # Final evaluation and statistics
        final_results = self._generate_final_results(training_duration)
        
        # Save final results
        final_results_file = self.save_dir / "final_training_results.json"
        with open(final_results_file, 'w') as f:
            json.dump(self._make_json_serializable(final_results), f, indent=2)
        
        logger.info(f"\nðŸŽ‰ Training Complete!")
        logger.info(f"Total duration: {training_duration:.1f}s")
        logger.info(f"Rounds completed: {self.current_round}")
        logger.info(f"Results saved to: {self.save_dir}")
        
        return final_results

    def _generate_final_results(self, training_duration: float) -> Dict[str, Any]:
        """Generate comprehensive final training results"""
        # Final model evaluation
        final_evaluation = self._evaluate_global_model()
        
        # Privacy budget summary
        privacy_summary = {}
        for node_id, accountant in self.privacy_accountants.items():
            privacy_summary[node_id] = accountant.get_privacy_stats()
        
        # Training statistics
        training_stats = {
            'total_rounds': self.current_round,
            'total_duration_seconds': training_duration,
            'average_round_duration': training_duration / max(1, self.current_round),
            'convergence_achieved': self.convergence_monitor.convergence_history[-1] if self.convergence_monitor.convergence_history else False
        }
        
        return {
            'training_completed': True,
            'timestamp': datetime.now().isoformat(),
            'final_evaluation': final_evaluation,
            'privacy_summary': privacy_summary,
            'training_statistics': training_stats,
            'model_info': self.global_model.get_model_info() if hasattr(self.global_model, 'get_model_info') else {},
            'configuration': self.config,
            'training_history': self.training_history
        }

    def save_trained_models(self):
        """Save all trained models"""
        models_dir = self.save_dir / "trained_models"
        models_dir.mkdir(exist_ok=True)
        
        # Save global model
        torch.save(
            self.global_model.state_dict(),
            models_dir / "global_model.pth"
        )
        
        # Save node models
        for node_id, model in self.models.items():
            torch.save(
                model.state_dict(),
                models_dir / f"{node_id}_model.pth"
            )
        
        logger.info(f"Models saved to {models_dir}")

    def _train_client(self, node_id: str, model: nn.Module) -> Dict[str, float]:
        """Train client model for one round
        
        Args:
            node_id: Client node identifier
            model: Client model to train
            
        Returns:
            Dictionary containing training statistics
        """
        model.train()
        device = next(model.parameters()).device
        optimizer = self.optimizers[node_id]
        criterion = nn.CrossEntropyLoss()
        
        # Initialize statistics
        total_loss = 0.0
        correct = 0
        total = 0
        num_samples = 0
        
        # Get client's data loader
        data_loader = self.data_loaders[node_id]
        
        # Training loop with progress bars
        num_epochs = self.config.get('client_epochs', 1)
        epoch_pbar = trange(num_epochs, desc=f"{node_id} Epochs", leave=False)
        
        for epoch in epoch_pbar:
            epoch_loss = 0.0
            epoch_correct = 0
            epoch_total = 0
            epoch_samples = 0
            
            # Add progress bar for batches
            batch_pbar = tqdm(data_loader, desc=f"Batches", leave=False)
            for batch_idx, (data, targets) in enumerate(batch_pbar):
                data, targets = data.to(device), targets.to(device)
                batch_size = data.size(0)
                
                optimizer.zero_grad()
                # Model returns (logits, features) - we only need logits for training
                outputs, _ = model(data)
                loss = criterion(outputs, targets)
                
                # Apply differential privacy if enabled
                if self.config.get('enable_differential_privacy_federated', True):
                    accountant = self.privacy_accountants[node_id]
                    if not accountant.is_budget_exhausted():
                        # Calculate privacy cost for this batch
                        dataset_size = len(data_loader.dataset)
                        privacy_cost = self._calculate_privacy_cost(batch_size, dataset_size)
                        
                        # Apply DP and consume privacy budget
                        loss = accountant.apply_dp(loss, model.parameters())
                        accountant.consume_privacy_budget(privacy_cost)
                    else:
                        logger.warning(f"âš ï¸ {node_id}: Privacy budget exhausted, skipping DP")
                
                loss.backward()
                
                # Gradient clipping for stability
                if self.config.get('max_grad_norm', 1.0) > 0:
                    torch.nn.utils.clip_grad_norm_(
                        model.parameters(),
                        self.config.get('max_grad_norm', 1.0)
                    )
                
                optimizer.step()
                
                # Update statistics
                epoch_loss += loss.item() * batch_size  # Multiply by batch size
                epoch_samples += batch_size
                _, predicted = outputs.max(1)
                epoch_total += targets.size(0)
                epoch_correct += predicted.eq(targets).sum().item()
                
                # Update batch progress bar
                batch_pbar.set_postfix({
                    'loss': f"{loss.item():.4f}",
                    'acc': f"{predicted.eq(targets).sum().item() / targets.size(0):.3f}"
                })
                
                # Log batch statistics if stats tracker is available
                if self.stats_tracker and batch_idx % 10 == 0:
                    self.stats_tracker.log_client_batch(
                        self.current_round,
                        node_id,
                        epoch,
                        batch_idx,
                        {
                            'loss': loss.item(),
                            'accuracy': predicted.eq(targets).sum().item() / targets.size(0)
                        }
                    )
            
            # Update epoch statistics
            total_loss += epoch_loss
            num_samples += epoch_samples
            correct += epoch_correct
            total += epoch_total
            
            # Update epoch progress bar
            epoch_pbar.set_postfix({
                'loss': f"{epoch_loss/epoch_samples:.4f}",
                'acc': f"{epoch_correct/epoch_total:.3f}"
            })
            
            # Log epoch statistics if stats tracker is available
            if self.stats_tracker:
                self.stats_tracker.log_client_epoch(
                    self.current_round,
                    node_id,
                    epoch,
                    {
                        'loss': epoch_loss / epoch_samples,  # Average by samples in epoch
                        'accuracy': epoch_correct / epoch_total
                    }
                )
        
        # Calculate final statistics
        avg_loss = total_loss / num_samples if num_samples > 0 else float('inf')  # Average by total samples
        accuracy = correct / total if total > 0 else 0.0
        
        # Log final client statistics if stats tracker is available
        if self.stats_tracker:
            self.stats_tracker.log_client_stats(
                self.current_round,
                node_id,
                {
                    'loss': avg_loss,
                    'accuracy': accuracy
                }
            )
        
        return {
            'loss': avg_loss,
            'accuracy': accuracy
        }


class ConvergenceMonitor:
    """Monitor training convergence with patience-based early stopping"""
    
    def __init__(self, patience: int = 10, min_delta: float = 0.001):
        self.patience = patience
        self.min_delta = min_delta
        self.best_accuracy = 0.0
        self.rounds_without_improvement = 0
        self.convergence_history = []
        
    def check_convergence(self, current_accuracy: float, current_loss: float) -> Tuple[bool, Dict]:
        """Check if model has converged"""
        improvement = current_accuracy - self.best_accuracy
        
        if improvement > self.min_delta:
            self.best_accuracy = current_accuracy
            self.rounds_without_improvement = 0
        else:
            self.rounds_without_improvement += 1
            
        self.convergence_history.append({
            'accuracy': current_accuracy,
            'loss': current_loss,
            'improvement': improvement,
            'rounds_without_improvement': self.rounds_without_improvement
        })
        
        converged = self.rounds_without_improvement >= self.patience
        
        return converged, {
            'status': 'converged' if converged else 'training',
            'rounds_without_improvement': self.rounds_without_improvement,
            'best_accuracy': self.best_accuracy,
            'current_accuracy': current_accuracy,
            'improvement': improvement
        }


class BiometricDataset(Dataset):
    """Custom dataset for biometric data with identity labels"""
    
    def __init__(self, images: List, identity_labels: List, transform=None):
        self.images = images
        self.identity_labels = identity_labels
        self.transform = transform
        
    def __len__(self):
        return len(self.images)
    
    def __getitem__(self, idx):
        image = self.images[idx]
        identity_label = self.identity_labels[idx]
        
        if self.transform:
            image = self.transform(image)
            
            return image, identity_label


def create_training_config() -> Dict[str, Any]:
    """Create default training configuration"""
    return {
        'num_identities': 300,
        'learning_rate': 0.001,
        'global_learning_rate': 0.01,
        'weight_decay': 1e-4,
        'local_epochs': 5,
        'max_epsilon': 1.0,
        'delta': 1e-5,
        'noise_multiplier': 1.0,
        'max_grad_norm': 1.0,
        'patience': 10,
        'min_delta': 0.001,
        'use_homomorphic_encryption': True,
        'batch_size': 32
    }


if __name__ == "__main__":
    # Example usage
    print("Privacy-Infused Federated Biometric Training System")
    print("This module provides comprehensive privacy-preserving federated learning")
    print("for biometric authentication systems.")
    
    # Create sample configuration
    config = create_training_config()
    print(f"\nDefault configuration:")
    for key, value in config.items():
        print(f"  {key}: {value}") 